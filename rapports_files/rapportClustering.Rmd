---
title: "RAPPORT"
author: "SAMA Fousseni"
date: "22/05/2022"
output: word_document
---

```{r message=FALSE, warning=FALSE}

# Chargement de packages
library("tidyverse")
library("FactoMineR")
library("factoextra")
library("ggpubr")
library(flextable)
```

# Compte rendu de la rencontre du 17 Août 2022
Dans le cadre du suivi des activité des recherche de Fousseni SAMA, une rencontre de cadrage s'est tenue le 17 Août 2022 dans les locaux du pavillon Ferdinand-Vandry de l’université Laval. Bien avant la rencontre, quelques corrections ont été apportées aux résulats précédemment envoyés et furent renvoyés pour observation.

```{r}
load("rdata/cells_matrix.rda")
################### Distribution ################
nrep_CRHs = apply(cells_matrix$block1,2,sum)
hist(nrep_CRHs)
summary(nrep_CRHs)

nrep_cells = apply(cells_matrix$block1,1,sum)
hist(nrep_cells)
summary(nrep_cells)
```

Les premières discussion de la rencontre ont porté sur les nouvelles données partagées concernant les cellules et CRHs. Une vue d'ensemble sur la distribution du nombre de CRHs fut faite sur le premier block. Après analyse il a été deduit qu'on avait un nombre assez élevé de CRHs d'autant puisque c'est le premier block qui fut exploré. Par la suite, afin d'avoir une idée claire sur la composition des CRHs, il a été proposé d'étudier leur complexité. En d'autres termes, de cette étude, doit ressortir le nombre de promoters et d'enhancers par CRHs.

Par la suite, étant donné l'objectif de la présente démarche (construire des clusters de cellules), les prochaines étapes consitent à construire un clustering de cellules à partir d'une méthode l'analyse multidimensionnelle, plus précisement de l'ACM. Pour ce fait, il a été convenu qu'un rapport sera produit afin de mettre le lumière les grandes lignes des étapes suivies.

En ce qui concerne la deuxième partie du traitement des données simulées, elle a été déjà entammée. Les prochaines étapes, consistent à appliquer la méthode de clustering des cellules proposée par *Higachi (Ruochi Zhang et al)* puis celle de *HiCImpute (Qing Xie et al)*.

Pour la prochaine rencontre, la date du mercredi 24 août 2022 à 14H a été retenue. Comme la rencontre passée, elle se tiendra dans le pavillon Ferdinand-Vandry de l’université Laval.

# Etude de la complexité des CRHs

## Première partie

L'objet crhs_complexity, comporte par block et par CRH le nombre de promoters et d'Enhancers. Dans le code qui suit, on résume ces informations.

```{r message=FALSE, warning=FALSE}
# Chargement des données
load("rdata/all_net_result.rda")

# result <- all_net_result$block1$resume_fusion%>%
#   str_split("-", simplify = TRUE)
# 
# result <- gsub(",.*","",result)
# result <- gsub(".* ","",result)
crhs_complexity = matrix(
  NA,
  nrow = 316*16,
  ncol = 3
)
line = 0
  
for (i in 1:16) {
  n_crhs = length(all_net_result[[i]]$crhs)
  
  for (j in seq_len(n_crhs)) {
    crhs_complexity[line + j, 1] = paste0("block", sprintf("%02d", i))
    crhs_complexity[line + j, 2] = nrow(all_net_result[[i]]$crhs[[j]]$mat_incidence)
    crhs_complexity[line + j, 3] = ncol(all_net_result[[i]]$crhs[[j]]$mat_incidence)
  }
  line = n_crhs + line
}
crhs_complexity = crhs_complexity[!is.na(crhs_complexity[, 1]), ]
colnames(crhs_complexity) <- c("Blocks", "Promoters", "Enhancers")
crhs_complexity <- tibble(data.frame(crhs_complexity))%>%
  mutate(
    Promoters = as.numeric(Promoters),
    Enhancers = as.numeric(Enhancers)
  )
```

Les tableaux ci-dessous, résument les informations sur les promoters et les enhancers des différents CRHs. Dans le tableau des promoters comme des enhancers sont en rouge les blocs où l'on trouve généralement des CRHs avec 1 promoter connecté à un enhancer (a cet effet un accent particulier a été mis sur la médiane, la moyenne et le troisième quartile).

```{r}
myTable_pr <- crhs_complexity%>%
  group_by(Blocks)%>%
  summarise(
    nb = n(),
    min_pr = min(Promoters),
    first_Qu_pr = quantile(Promoters, probs = 0.25),
    median_pr = median(Promoters),
    mean_pr = round(mean(Promoters), 3),
    third_Qu_pr = quantile(Promoters, probs = 0.75),
    max_pr = max(Promoters)
  )

apply(myTable_pr[, 2], 2, sum, na.rm = TRUE)

myFxTable_pr <- flextable(
  myTable_pr, 
  col_keys = c("Blocks", "nb", "min_pr", "first_Qu_pr", "median_pr", "mean_pr", "third_Qu_pr", "max_pr")
)

myFxTable_pr <- color(myFxTable_pr, ~ median_pr <2, ~ median_pr, color = "red")
myFxTable_pr <- bold(myFxTable_pr, ~ median_pr < 2, ~ median_pr, bold = TRUE)
myFxTable_pr <- color(myFxTable_pr, ~ mean_pr <2, ~ mean_pr, color = "red")
myFxTable_pr <- bold(myFxTable_pr, ~ mean_pr < 2, ~ mean_pr, bold = TRUE)
myFxTable_pr <- color(myFxTable_pr, ~ third_Qu_pr <2, ~ third_Qu_pr, color = "red")
myFxTable_pr <- bold(myFxTable_pr, ~ third_Qu_pr < 2, ~ third_Qu_pr, bold = TRUE)

myFxTable_pr

myTable_enh <- crhs_complexity%>%
  group_by(Blocks)%>%
  summarise(
    min_en = min(Enhancers),
    first_Qu_en = quantile(Enhancers, probs = 0.25),
    median_en = median(Enhancers),
    mean_en = round(mean(Enhancers), 3),
    third_Qu_en = quantile(Enhancers, probs = 0.75),
    max_en = max(Enhancers)
  )

myFxTable_en <- flextable(
  myTable_enh, 
  col_keys = c("Blocks", "min_en", "first_Qu_en", "median_en", "mean_en", "third_Qu_en", "max_en")
)

myFxTable_en <- color(myFxTable_en, ~ median_en <2, ~ median_en, color = "red")
myFxTable_en <- bold(myFxTable_en, ~ median_en < 2, ~ median_en, bold = TRUE)
myFxTable_en <- color(myFxTable_en, ~ mean_en <2, ~ mean_en, color = "red")
myFxTable_en <- bold(myFxTable_en, ~ mean_en < 2, ~ mean_en, bold = TRUE)
myFxTable_en <- color(myFxTable_en, ~ third_Qu_en <2, ~ third_Qu_en, color = "red")
myFxTable_en <- bold(myFxTable_en, ~ third_Qu_en < 2, ~ third_Qu_en, bold = TRUE)

myFxTable_en

```


## Deuxième partie 
Ce tableau donne le nombre total de CRH avec exactement 1 promoteur et 1 enhancer, 1 promoteur et 2 enhancers, 2 promoteurs et 1 enhancer.

```{r}
fxTable <- crhs_complexity%>%
  filter(Promoters == 1 & Enhancers == 1)%>%
  group_by(Blocks)%>%
  summarise(
    n = n()
  )%>%
  rename("1_promoter_1_enhancer" = n)%>%
  left_join(
    crhs_complexity%>%
  filter(Promoters == 1 & Enhancers == 2)%>%
  group_by(Blocks)%>%
  summarise(
    n = n()
  )%>%
  rename("1_promoter_2_enhancers" = n),
  "Blocks"
  )%>%
  left_join(
    crhs_complexity%>%
  filter(Promoters == 2 & Enhancers == 1)%>%
  group_by(Blocks)%>%
  summarise(
    n = n()
  )%>%
  rename("2_promoter_1_enhancer" = n),
  "Blocks"
  )
  
flextable(
  fxTable%>%
    bind_rows(
      apply(fxTable[, 2:4], 2, sum, na.rm = TRUE)
    )
)
```


# Analyse des correspondances multiples

```{r message=FALSE, warning=FALSE}
cells_data <- cells_matrix$block1
cells_data[cells_data == 1] <- "in"
cells_data[cells_data == 0] <- "Not in"

cells_data <- data.frame(cells_data)
```

## Présentation des données

Les données sur lesquelles nous travaillons sont qualitatives. Notre polutaion est constituées de cellules (en ligne) et en colonne on peut lire les différents CRHs que l'on retrouve ou non dans les cellules ("In" si on retrouve le CRH dans une cellule donnée, "Not in" sinon). Au total, on compte 250 cellules et 316 CRHs.

## Construction de l'ACM

```{r message=FALSE, warning=FALSE, results='hide'}

# Construction de l'ACM
res.mca <- MCA(cells_data, graph = FALSE)
get_eigenvalue(res.mca)
head(res.mca$ind$cos2)
```

L'ACM ne s'applique pas directement sur les données (qualitatives) brutes. Une transformation du tableau de départ est faite pour obtenir un tableau dijonctif complet (TDC). Notons par $n$ le nombre de cellules (250) et par $K$ le nombre de CRHs (316) présent dans notre tableau de données. Pour un CRH $k$ (telle que $1 \le k \le K$) donnée, notons par $J_k$ le nombre de modalités (2 dans notre cas). Pour une cellule $i$ tel que $1 \le i \le n$, la valeur $y_{ijk}$ du TDC vaut : $y_{ijk} = \begin{cases} 1  \text{ si la cellule i prend la modalité j pour la variable k}\\ 0 \text{ sinon}  \end{cases}$. Le tableau est dijonctif en ce sens que chaque modalité d'une même variable s'exclu mutuellement : $\sum_{j \in J_k}y_{ijk} = 1$. Il est dit complet en ce sens qu’à tout individu $i$ correspond une et une seule modalité pour une variable $k$ donnée. A cet effet, $\sum_{K}\sum_{j \in J_k}y_{ijk} = K$ dans notre cas.

Dans cette étude, nous nous interressons au profil des cellules afin d'en degager les typologies. En utilisant le tableau logique (TDC), deux cellules données se resemblenet s'ils ont en commun un grand nombre de CRHs.

Pour chaque individu $i$ de notre population de cellules est affecté un poids $p_i = \frac{1}{n}$. La distance entre deux cellules $i$ et $i'$ est donnée par :
$$d^2(i, i') = \sum_{k \in K}\frac{n}{Kn_{.k}}(y_{i.k} - y_{i'.k}) $$
$n_{.k}$ étant le nombre de cellules ayant en commun le CRH $k$ et $y_{i.k}$ désigne la valeur prise par la cellule $i$ pour un crh $k$ ("In", "Not in") telle que $(y_{i.k} - y_{i'.k})^2 \in \{0, 1\}$.

Par l'expression de la distance précédente, il est ressort que deux cellules $i$ et $i'$ sont proches s’ils ont en commun un grand nombre de CRHs.

```{r message=FALSE, warning=FALSE}

# fviz_mca_biplot(res.mca, repel = TRUE, ggtheme = theme_minimal())
# fviz_mca_var(res.mca, choice = "mca.cor", repel = TRUE)
#fviz_mca_var(res.mca, repel = TRUE, select.var = list(cos2 = 0.04), ggtheme= theme_minimal())
# fviz_mca_var(res.mca, choice = "quanti.sup", ggtheme = theme_minimal())
#fviz_mca_ind(res.mca, ggtheme = theme_minimal())
# Coloration des individus en fonction de leur cosinus
fviz_mca_ind(res.mca, col.ind = "cos2", gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"), repel = TRUE, ggtheme = theme_minimal())
# Filtrer les individus
#fviz_mca_ind(res.mca, select.ind = list(cos2 = 0.04), ggtheme = theme_minimal())
```

L'interprétation des résulats de l'ACM et de l'ACP sont similaire. En effet, les points du nuage des individus ayant des fortes contributions sont ceux qui sont responsable de la formation des axes factoriels. Ceux ayant un $cos^2$ elevé, permettent de donner une interpretation aux axes factoriels.

Nous nous interessons particulièrement au nuage des individus. Cependant afin de ne pas faire d'interpretation erronée, nous nous reservons de commenter les résulats obtenus sur un plan. En effet, étant donnée que la contribution des axes est relativement faible (<=3%), la projection des points (cellules) pourrait ne pas refléter les vraies typologies. Etant donnée que toutes nos varibles sont qualitatives (donc denotent peu de variabilité), la contribution assez faible des différents axes factoriels était prévisible. Pour toutes ces raisons, nous allons nous focaliser sur la classification des cellules.

## Classification des cellules

Il est question dans cette partie de réaliser la classification hiérarchique de notre population de cellules. Pour ce fait, la classification ne se fera pas directement sur les données brutes. En effet, nous partirons des résulats issus de l'analyse en composante multiple (ACM) réalisée précédemment, afin d'extraire les coordonnées factoriels des cellules sur un nombre d'axes choisi au préalable. Ainsi, des données qualitatives de départ, nous nous ramenons à  des données quatitatives avec lesquelles il est plus aisé de construire des classes.

```{r}
head(res.mca$eig)
which(res.mca$eig[, 3, drop = FALSE]>=60)[1:5]
```
Etant donné que les premières dimensions ont de faibles valeurs propres, afin d'obtenir un pourcentage de variance acceptable (au moins 60%), nous prendrons au moins les 59 premiers axes. 

```{r message=FALSE, warning=FALSE}
# On refait l'ACM, en conservant que les 60 premiers axes
res.mca_ <- MCA(cells_data, ncp = 70, graph = FALSE)
# Construction de la classification
## kk : si = Inf, on ne voudrait pas faire de méthode de partitionnement 
## avant de construire la classification. Si un nombre est précisé 
## (100 par exemple), on procède à une partition en 100 classes avant de 
## procéder à la classification. Utile quand on a un jeux de données important
## min  et max : permettent de préciser entre quelle valeur minimale et 
## maximale nous allons chercher le nombre de classes optiales
## consol = TRUE : on veut la consolidation des classes à l'issu de 
## la classification
## Pour le reste des arguments, nous laissons par défaut
hcpc_cluster <- HCPC(res.mca_, kk=Inf, min = 4, max = 5, graph = FALSE)
# Le dendogram
#fviz_dend(hcpc_cluster, cex = 0.7, palette = "jco", rect = TRUE, rect_fill = TRUE, rect_border = "jco")
# Graphique
fviz_cluster(hcpc_cluster, repel = TRUE, geom = "point", main = "Classification des cellules")
```


